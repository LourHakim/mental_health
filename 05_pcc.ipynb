{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install missingno"
      ],
      "metadata": {
        "id": "-UgBdCyuM2hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfPecSvkJb1T"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandas.api.types import CategoricalDtype\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn as skl\n",
        "import missingno as msno\n",
        "from scipy.stats import chi2_contingency\n",
        "from tqdm import tqdm\n",
        "import scipy.stats as st\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.colors as mcolors\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, log_loss, mean_squared_error\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from itertools import combinations\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import roc_curve, auc, log_loss\n",
        "from itertools import product\n",
        "from collections import Counter\n",
        "from sklearn.base import clone\n",
        "from sklearn.metrics import accuracy_score, hamming_loss\n",
        "from sklearn.utils import check_X_y, check_array\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict, StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "import shap"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCC"
      ],
      "metadata": {
        "id": "vqAlLjFcVXQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_df = pd.read_csv('OutputData/mental_health_full.csv')\n",
        "\n",
        "# ------------------ 1. Data Preparation ------------------ #\n",
        "df_pcc = full_df[\n",
        "    full_df['q26'].isin([0, 1]) &\n",
        "    full_df['q27'].isin([0, 1]) &\n",
        "    full_df['q84_binary'].isin([0, 1])\n",
        "].copy()\n",
        "\n",
        "X_pcc = df_pcc.drop(columns=['q26', 'q27', 'q84', 'q84_binary', 'state', 'sitename', 'q28'])\n",
        "Y_pcc = df_pcc[['q26', 'q27', 'q84_binary']]\n",
        "\n",
        "X_pcc = X_pcc.select_dtypes(include=[float, int]).dropna()\n",
        "Y_pcc = Y_pcc.loc[X_pcc.index]\n",
        "\n",
        "X_train_pcc, X_test_pcc, Y_train_pcc, Y_test_pcc = train_test_split(\n",
        "    X_pcc, Y_pcc, test_size=0.3, random_state=42, stratify=Y_pcc['q26']\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_pcc[['bmipct']] = scaler.fit_transform(X_train_pcc[['bmipct']])\n",
        "X_test_pcc[['bmipct']] = scaler.transform(X_test_pcc[['bmipct']])\n",
        "\n",
        "# ------------------ 2. PCC Class ------------------ #\n",
        "class ProbabilisticClassifierChain:\n",
        "    def __init__(self, baselearner):\n",
        "        self.baselearner = baselearner\n",
        "        self.r_ = None\n",
        "        self.fitted_ = None\n",
        "        self.patterns_ = None\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        x, y = check_X_y(x, y, multi_output=True)\n",
        "        _, r = y.shape\n",
        "        self.r_ = r\n",
        "        self.fitted_ = []\n",
        "        self.patterns_ = [list(p) for p in product(*(r * [range(2)]))]\n",
        "        for i in range(r):\n",
        "            _x = np.column_stack([x, y[:, :i]]) if i > 0 else x\n",
        "            _y = y[:, i]\n",
        "            model = clone(self.baselearner, safe=False)\n",
        "            model.fit(_x, _y)\n",
        "            self.fitted_.append(model)\n",
        "        return self\n",
        "\n",
        "    def predict_proba_of(self, x, y):\n",
        "        _x = x.copy()\n",
        "        if len(y.shape) == 1:\n",
        "            y = y.reshape(1, self.r_)\n",
        "        idx = np.arange(len(x))\n",
        "        res = self.fitted_[0].predict_proba(_x)[idx, y[:, 0]]\n",
        "        for i in range(1, self.r_):\n",
        "            _x = np.column_stack([_x, np.ones(len(x)) * y[:, i - 1]])\n",
        "            res *= self.fitted_[i].predict_proba(_x)[idx, y[:, i]]\n",
        "        return res\n",
        "\n",
        "    def predict(self, x):\n",
        "        x = check_array(x)\n",
        "        pattern_matrix = np.array([self.predict_proba_of(x, np.array(p)) for p in self.patterns_]).T\n",
        "        max_indices = np.argmax(pattern_matrix, axis=1)\n",
        "        return np.array([self.patterns_[i] for i in max_indices])\n",
        "\n",
        "# ------------------ 3. Train ------------------ #\n",
        "pcc_model = ProbabilisticClassifierChain(LogisticRegression(solver='liblinear', max_iter=1000))\n",
        "pcc_model.fit(X_train_pcc.to_numpy(), Y_train_pcc.to_numpy())\n",
        "\n",
        "# ------------------ 4. Extract Top Features ------------------ #\n",
        "\n",
        "top_features_per_target = []\n",
        "\n",
        "# Loop through each fitted model and collect top features\n",
        "for i, clf in enumerate(pcc_model.fitted_):\n",
        "    coefs = clf.coef_.ravel()\n",
        "    valid_indices = np.arange(len(coefs))\n",
        "    abs_coefs = np.abs(coefs)\n",
        "\n",
        "    # Sort and select top indices safely\n",
        "    top_indices = valid_indices[np.argsort(abs_coefs)[::-1][:min(10, len(coefs))]]\n",
        "\n",
        "    # Get column names for top features\n",
        "    top_feats = [X_train_pcc.columns[i] for i in top_indices if i < X_train_pcc.shape[1]]\n",
        "    top_features_per_target.extend(top_feats)\n",
        "\n",
        "# Count frequency of each feature\n",
        "top_counts = Counter(top_features_per_target)\n",
        "\n",
        "# Show 10 most common features across all 3 sub-models\n",
        "print(\"\\nTop 10 Most Frequent Features Across PCC Sub-models:\")\n",
        "for feat, count in top_counts.most_common(10):\n",
        "    label = feature_labels.get(feat, feat)\n",
        "    print(f\"- {label} (appeared in {count}/3 models)\")\n",
        "\n",
        "\n",
        "# ------------------ 5. Evaluation Metrics ------------------ #\n",
        "\n",
        "# Predict\n",
        "Y_pred = pcc_model.predict(X_test_pcc.to_numpy())\n",
        "Y_true = Y_test_pcc.to_numpy()\n",
        "\n",
        "# (a) Accuracy per target\n",
        "print(\"\\n(a) Accuracy per Target:\")\n",
        "for i, col in enumerate(Y_test_pcc.columns):\n",
        "    acc = accuracy_score(Y_true[:, i], Y_pred[:, i])\n",
        "    print(f\"Accuracy for {col}: {acc:.4f}\")\n",
        "\n",
        "# (b) Hamming Loss (average error per variable)\n",
        "print(\"\\n(b) Hamming Loss (average error per variable):\")\n",
        "print(f\"{hamming_loss(Y_true, Y_pred):.4f}\")\n",
        "\n",
        "# (c) Exact Match (0/1 Loss) â€“ all targets predicted correctly\n",
        "print(\"\\n(c) Exact Match (0/1 Loss):\")\n",
        "exact_match = np.mean(np.all(Y_true == Y_pred, axis=1))\n",
        "print(f\"{exact_match:.4f}\")\n",
        "\n",
        "# (d) Log Loss (multi-output, joint probability of full target vector)\n",
        "print(\"\\n(d) Log Loss (multi-output):\")\n",
        "probs = np.column_stack([\n",
        "    pcc_model.predict_proba_of(X_test_pcc.to_numpy(), np.array(p))\n",
        "    for p in pcc_model.patterns_\n",
        "])\n",
        "\n",
        "true_patterns = [tuple(row) for row in Y_true]\n",
        "pattern_map = {tuple(p): i for i, p in enumerate(pcc_model.patterns_)}\n",
        "true_indices = [pattern_map[tuple(p)] for p in true_patterns]\n",
        "true_probs = probs[np.arange(len(probs)), true_indices]\n",
        "logloss = -np.mean(np.log(true_probs + 1e-10))  # Add epsilon for stability\n",
        "print(f\"{logloss:.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\n(e) False Positive Rate (FPR) and False Negative Rate (FNR) per Target:\")\n",
        "for i, col in enumerate(Y_test_pcc.columns):\n",
        "    cm = confusion_matrix(Y_true[:, i], Y_pred[:, i])\n",
        "    tn, fp, fn, tp = cm.ravel() if cm.shape == (2, 2) else (0, 0, 0, 0)\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
        "    print(f\"{col}: FPR = {fpr:.4f}, FNR = {fnr:.4f}\")\n"
      ],
      "metadata": {
        "id": "KASA6SrBVUyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f653e84-2fa5-47f0-d9d9-6192675eb239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Most Frequent Features Across PCC Sub-models:\n",
            "- gdp 2023 (appeared in 3/3 models)\n",
            "- Mean household income (appeared in 3/3 models)\n",
            "- Unemployment Rate(Percent) (appeared in 3/3 models)\n",
            "- Sexual and gender identity (appeared in 3/3 models)\n",
            "- Saw physical violence in neighborhood (appeared in 3/3 models)\n",
            "- Sex (appeared in 2/3 models)\n",
            "- Ever had sexual intercourse (appeared in 2/3 models)\n",
            "- Electronic bullying (past 12 months) (appeared in 2/3 models)\n",
            "- Bullying at school (past 12 months) (appeared in 2/3 models)\n",
            "- BMI percentile (appeared in 2/3 models)\n",
            "\n",
            "(a) Accuracy per Target:\n",
            "Accuracy for q26: 0.5726\n",
            "Accuracy for q27: 0.8299\n",
            "Accuracy for q84_binary: 0.7241\n",
            "\n",
            "(b) Hamming Loss (average error per variable):\n",
            "0.2911\n",
            "\n",
            "(c) Exact Match (0/1 Loss):\n",
            "0.5062\n",
            "\n",
            "(d) Log Loss (multi-output):\n",
            "1.7560\n",
            "\n",
            "(e) False Positive Rate (FPR) and False Negative Rate (FNR) per Target:\n",
            "q26: FPR = 0.0000, FNR = 1.0000\n",
            "q27: FPR = 0.0000, FNR = 1.0000\n",
            "q84_binary: FPR = 0.0000, FNR = 1.0000\n"
          ]
        }
      ]
    }
  ]
}